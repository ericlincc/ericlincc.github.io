<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Cheuk Yin (Eric) Lin</title>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B27JJHFGNT"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-B27JJHFGNT');
</script>

</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Cheuk Yin (Eric) Lin</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://ericlincc.com"><img src="assets/eric_lin.jpg" alt="Profile picture unavailable" width="280px" height="280px" /></a>&nbsp;</td>
<td align="left"><p>Research Scientist,<br /> Meta Platforms, Inc.<br />
Email: cylin AT cs DOT wisc DOT edu <br />
[<a href="https://www.linkedin.com/in/ericlincc/">Linkedin</a>] [<a href="https://scholar.google.com/citations?user=p7uC0pUAAAAJ&amp;hl=en">Google Scholar</a>]</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a research scientist at Meta, working on large-scale deep learning ranking models for modern recommendation systems. I am primarily interested in the area of large-scale optimization algorithms and their applications to machine learning and deep learning. My current research work aims to design novel optimization algorithms with solid theoretical guarantees and good practical performance.</p>
<p>I obtained my Ph.D. degree in Computer Science at the University of Wisconsin-Madison and was fortunate to be advised by <a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>. Before moving to Madison, I completed my M.S. degree in Computer Science at Boston Unversity, where I had the great opportunity to work on convex optimization with <a href="http://orecchia.net">Prof. Lorenzo Orecchia</a> and Jelena. Prior to that, I obtained my B.A. degree in Mathematics at the University of Cambridge, supervised by <a href="https://www.chu.cam.ac.uk/people/view/christopher-tout">Professor Christopher Tout</a> and <a href="https://www.chu.cam.ac.uk/people/view/paul-russell">Dr Paul Russell</a>.</p>
<h2>News</h2>
<ul>
<li><p>Sep 2024: <a href="https://neurips.cc/virtual/2024/poster/93484">Shuffled SGD</a> is accepted to <i>NeurIPS&rsquo;24</i>!</p>
</li>
</ul>
<ul>
<li><p>Apr 2023: <a href="https://arxiv.org/abs/2303.16279">ACODER</a> is accepted to <i>ICML&rsquo;23</i>!</p>
</li>
</ul>
<ul>
<li><p>Sep 2022: <a href="https://arxiv.org/abs/2111.01842">CLVR</a> is accepted to <i>NeurIPS&rsquo;22</i>!</p>
</li>
</ul>
<ul>
<li><p>May 2022: I presented our work (<a href="https://arxiv.org/abs/2111.01842">CLVR</a>) during 2022 Optimization Days at HEC Montréal.</p>
</li>
</ul>
<ul>
<li><p>May 2021: <a href="https://arxiv.org/abs/2102.06806">Parameter-free Locally Accelerated Conditional Gradients</a> is accepted to <i>ICML&rsquo;21</i>!</p>
</li>
</ul>
<h2>Experience</h2>
<ul>
<li><p>Research Scientist | Modern Recommendation Systems AI, Meta
<br /> Aug 2024 - Present
<br /> Menlo Park, CA, United States</p>
</li>
</ul>
<ul>
<li><p>Applied Scientist Intern | Machine Intelligence and Decision Analytics for Search, Amazon
<br /> May 2021 - Aug 2021
<br /> Berkeley, CA, United States
<br /> Worked on a deep learning research project to improve the quality of Amazon's search query suggestions.</p>
</li>
</ul>
<ul>
<li><p>Software Development Engineer Intern | Machine Intelligence and Decision Analytics for Search, Amazon
<br /> Mar 2019 - Jan 2020
<br /> Berkeley, CA, United States
<br /> Worked on the machine learning infrastructure for customer search query understanding and suggestion.</p>
</li>
</ul>
<h2>Publications &amp; Preprints</h2>
<p>(* denotes equal contribution, α-β denotes alphabetical ordering)</p>
<ul>
<li><p>X. Cai*, C-Y. Lin*, J. Diakonikolas, “Tighter Convergence Bounds for Shuffled SGD via Primal-Dual Perspective”, in Proc. NeurIPS&rsquo;24, 2024. [<a href="https://arxiv.org/abs/2306.12498">arXiv</a>] [<a href="https://neurips.cc/virtual/2024/poster/93484">Poster</a>]</p>
</li>
</ul>
<ul>
<li><p>C-Y. Lin, C. Song, J. Diakonikolas, &ldquo;Accelerated Cyclic Coordinate Dual Averaging with Extrapolation for Composite Convex Optimization&rdquo;, in Proc. ICML&rsquo;23, 2023. [<a href="https://arxiv.org/abs/2303.16279">arXiv</a>]</p>
</li>
</ul>
<ul>
<li><p>C. Song*, C-Y. Lin*, S. Wright, J. Diakonikolas, &ldquo;Coordinate Linear Variance Reduction for Generalized Linear Programming&rdquo;, in Proc. NeurIPS&rsquo;22, 2022. [<a href="https://arxiv.org/abs/2111.01842">arXiv</a>] [<a href="https://neurips.cc/virtual/2022/poster/53988">Talk</a>] [<a href="https://neurips.cc/media/neurips-2022/Slides/53988.pdf">Poster</a>]</p>
</li>
</ul>
<ul>
<li><p>(α-β) A. Carderera, J. Diakonikolas, C. Y. Lin, S. Pokutta, &ldquo;Parameter-free Locally Accelerated Conditional Gradients&rdquo;, in Proc. ICML&rsquo;21, 2021. [<a href="https://arxiv.org/abs/2102.06806">arXiv</a>] [<a href="https://slideslive.com/38959171/parameterfree-locally-accelerated-conditional-gradients?ref=speaker-35525-latest">Talk</a>] [<a href="https://icml.cc/media/icml-2021/Slides/9511.pdf">Slides</a>]</p>
</li>
</ul>
<h2>Teaching</h2>
<ul>
<li><p>2023 Spring</p>
<ul>
<li><p><a href="https://www.jelena-diakonikolas.com/cs639-s23.html">CS 639 Foundations of Data Science</a> (<a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2022 Spring</p>
<ul>
<li><p><a href="https://www.jelena-diakonikolas.com/cs639-s22.html">CS 639 Foundations of Data Science</a> (<a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020 Fall</p>
<ul>
<li><p><a href="http://www.jelena-diakonikolas.com/cs726-f20.html">CS 726 Nonlinear Optimization</a> (<a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020 Spring</p>
<ul>
<li><p><a href="http://www.jelena-diakonikolas.com/cs726-s20.html">CS 726 Nonlinear Optimization</a> (<a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>)</p>
</li>
</ul>

</li>
</ul>
<h2>Relevant Courses</h2>
<ul>
<li><p>2022 Spring</p>
<ul>
<li><p><a href="https://pages.cs.wisc.edu/~yliang/cs839_spring22/index.html">CS 839 Theoretical Foundations of Deep Learning</a> (Prof. Yingyu Liang)</p>
</li>
<li><p>CS 787 Advanced Algorithms (Prof. Christos Tzamos)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2021 Fall</p>
<ul>
<li><p><a href="https://people.math.wisc.edu/~roch/hdps/index.html">Math 888 High-Dimensional Probability and Statistics</a> (Prof. Sebastien Roch)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2021 Spring</p>
<ul>
<li><p>CS 525 Linear Optimization (Prof. Alberto Del Pia)</p>
</li>
<li><p>CS 728 Integer Optimization (Prof. Jim Luedtke)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020 Fall</p>
<ul>
<li><p>CS 524 Introduction to Optimization (Prof. Michael Ferris)</p>
</li>
<li><p>CS 727 Convex Analysis (Prof. Stephen M. Robinson)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020 Spring</p>
<ul>
<li><p>CS 726 Nonlinear Optimization (<a href="http://www.jelena-diakonikolas.com">Prof. Jelena Diakonikolas</a>)</p>
</li>
<li><p>CS 761 Mathematical Foundations of Machine Learning (Prof. Robert Nowak &amp; Prof. Kangwook Lee)</p>
</li>
</ul>

</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-05-20 22:21:16 HKT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
